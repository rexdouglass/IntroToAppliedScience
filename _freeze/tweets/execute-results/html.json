{
  "hash": "c3d85feaaef4407784b5002131c96c34",
  "result": {
    "markdown": "::: {.cell hash='tweets_cache/html/unnamed-chunk-1_c6561b71a244f6ebd0e072dde8b17be9'}\n\n```{.r .cell-code}\ninstall.packages('V8')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nInstalling package into '/home/skynet3/R/x86_64-pc-linux-gnu-library/4.2'\n(as 'lib' is unspecified)\n```\n:::\n\n```{.r .cell-code}\n#library(V8)\n#cx <- v8()\n#cx$source(\"/home/skynet3/Downloads/twitter-2022-11-08-24fa1be25590defacf8df1fe45d475a1b82d1e6d6223a7c9cb10e61deff3c19d/data/tweets.js\") # now the variable 'data' is defined #in V8\n#cx$get(\"data\") \nfile=\"/home/skynet3/Downloads/twitter-2022-11-08-24fa1be25590defacf8df1fe45d475a1b82d1e6d6223a7c9cb10e61deff3c19d/data/tweets.js\"\nlibrary(jsonlite)\ndf <- fromJSON(file)\nnames(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"tweet\"\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks jsonlite::flatten()\n✖ dplyr::lag()     masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\ntweets <- df$tweet %>% janitor::clean_names()\ndim(tweets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 30185    21\n```\n:::\n\n```{.r .cell-code}\nnames(tweets)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"edit_info\"                 \"retweeted\"                \n [3] \"source\"                    \"entities\"                 \n [5] \"display_text_range\"        \"favorite_count\"           \n [7] \"id_str\"                    \"truncated\"                \n [9] \"retweet_count\"             \"id\"                       \n[11] \"possibly_sensitive\"        \"created_at\"               \n[13] \"favorited\"                 \"full_text\"                \n[15] \"lang\"                      \"extended_entities\"        \n[17] \"in_reply_to_status_id_str\" \"in_reply_to_user_id\"      \n[19] \"in_reply_to_status_id\"     \"in_reply_to_screen_name\"  \n[21] \"in_reply_to_user_id_str\"  \n```\n:::\n\n```{.r .cell-code}\ntweets$rex_rank <- as.numeric(tweets$retweet_count) + as.numeric(tweets$favorite_count)\nextended_entities <- tweets$extended_entities$media\ndim(extended_entities)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n```{.r .cell-code}\nextended_entities <- tweets$entities$urls\ndim(extended_entities)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n```{.r .cell-code}\ntweets$url <- sapply(tweets$entities$urls, FUN=function(x) { ifelse(is.null(x$expanded_url), NA, x$expanded_url) } ) %>% unlist()\ntweets_url <- tweets %>% filter(!is.na(url))\ndim(tweets_url)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 13155    23\n```\n:::\n\n```{.r .cell-code}\nView(tweets_url)\ntweets_url_small <- tweets_url %>% \n                    dplyr::select(created_at, full_text, rex_rank, url) %>%\n                    filter(!url %>% str_detect(\"twitter\")) %>%\n                    arrange(desc(rex_rank), url) \ndim(tweets_url_small)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10479     4\n```\n:::\n\n```{.r .cell-code}\ntweets_url_small %>% write.csv(\"/mnt/8tb_a/rwd_github_private/IntroToAppliedScience/git_ignore/temp.csv\")\ntweets_url_labeled <- read.csv(\"/mnt/8tb_a/rwd_github_private/IntroToAppliedScience/git_ignore/temp_labeled.csv\") #%>% filter(keep %in% 1)\ndim(tweets_url_labeled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7510    3\n```\n:::\n\n```{.r .cell-code}\ntweets_url_labeled_bk <- tweets_url_labeled\ndim(tweets_url_labeled_bk)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7510    3\n```\n:::\n\n```{.r .cell-code}\ntweets_url_labeled %>% \n  arrange(desc(rex_rank), url)  %>% filter(!duplicated(url)) %>% \n  filter(!url %>% str_detect(\"covid\")) %>% \n  #dim() %>%\n  write.csv(\"/mnt/8tb_a/rwd_github_private/IntroToAppliedScience/git_ignore/temp_labeled.csv\", row.names = FALSE)\ntweets_url_labeled <- read.csv(\"/mnt/8tb_a/rwd_github_private/IntroToAppliedScience/git_ignore/temp_labeled.csv\") #%>% filter(keep %in% 1)\ndim(tweets_url_labeled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 7510    3\n```\n:::\n\n```{.r .cell-code}\nfor(url in tweets_url_labeled$url[7601:7800]){browseURL(url=url)}\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}